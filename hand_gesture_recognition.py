import cv2
import numpy as np
from ultralytics import YOLO
import time
from PIL import Image, ImageDraw, ImageFont

# æ‰‹åŠ¿ç±»åˆ«æ˜ å°„
gesture_classes = {
    0: "æ•°å­—1",
    1: "æ•°å­—2",
    2: "æ•°å­—3",
    3: "æ•°å­—4",
    4: "æ•°å­—5",
    5: "å‰ªåˆ€",
    6: "é”¤å¤´",
    7: "å¸ƒ"
}

# åŠ è½½ä¸­æ–‡å­—ä½“
try:
    # å°è¯•åŠ è½½Windowsç³»ç»Ÿå­—ä½“
    FONT_PATH = "C:/Windows/Fonts/simhei.ttf"  # é»‘ä½“
    FONT = ImageFont.truetype(FONT_PATH, 24)
    print(f"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {FONT_PATH}")
except Exception as e:
    print(f"âŒ æ— æ³•åŠ è½½æŒ‡å®šå­—ä½“: {e}")
    print("ğŸ’¡ å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“")
    FONT = ImageFont.load_default()

class HandGestureRecognizer:
    def __init__(self, model_path=None):
        # åŠ è½½YOLOv8æ¨¡å‹
        if model_path:
            self.model = YOLO(model_path)
        else:
            # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œåç»­å¯ä»¥æ›¿æ¢ä¸ºè‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹
            self.model = YOLO('yolov8n.pt')
        
        # æ‰“å¼€æ‘„åƒå¤´
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # ç”¨äºè®¡ç®—å¸§ç‡
        self.prev_time = 0
        self.fps = 0
    
    def preprocess_frame(self, frame):
        """é¢„å¤„ç†å¸§å›¾åƒ"""
        # YOLOv8ä¼šè‡ªåŠ¨å¤„ç†å›¾åƒï¼Œè¿™é‡Œå¯ä»¥æ·»åŠ é¢å¤–çš„é¢„å¤„ç†æ­¥éª¤
        return frame
    
    def detect_gestures(self, frame):
        """æ£€æµ‹æ‰‹åŠ¿"""
        # è°ƒæ•´YOLOv8æ¨¡å‹å‚æ•°ï¼Œæé«˜è¯†åˆ«å‡†ç¡®ç‡
        # conf: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œæé«˜åˆ°0.6å‡å°‘è¯¯æ£€
        # iou: IOUé˜ˆå€¼ï¼Œæ§åˆ¶é‡å æ£€æµ‹æ¡†çš„åˆå¹¶
        # imgsz: è¾“å…¥å›¾åƒå¤§å°ï¼Œè°ƒæ•´ä¸º320x320æé«˜é€Ÿåº¦
        results = self.model(frame, 
                           conf=0.6,  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€
                           iou=0.5,   # IOUé˜ˆå€¼ï¼Œæ§åˆ¶é‡å æ£€æµ‹æ¡†
                           imgsz=320, # è¾“å…¥å›¾åƒå¤§å°ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®ç‡
                           verbose=False)
        return results
    
    def draw_results(self, frame, results):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒï¼Œç”¨äºç»˜åˆ¶ä¸­æ–‡
        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        
        # è§£ææ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                # è·å–ç½®ä¿¡åº¦
                conf = float(box.conf[0])
                # è·å–ç±»åˆ«
                cls = int(box.cls[0])
                
                # æ£€æŸ¥ç±»åˆ«æ˜¯å¦åœ¨æ‰‹åŠ¿æ˜ å°„ä¸­
                if cls in gesture_classes:
                    gesture_name = gesture_classes[cls]
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    # ç»˜åˆ¶ç±»åˆ«åç§°å’Œç½®ä¿¡åº¦ï¼ˆä½¿ç”¨PILç»˜åˆ¶ä¸­æ–‡ï¼‰
                    label = f"{gesture_name}: {conf:.2f}"
                    
                    # å°†PILå›¾åƒè½¬æ¢å›OpenCVå›¾åƒï¼Œç»˜åˆ¶ä¸­æ–‡
                    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(pil_img)
                    draw.text((x1, y1 - 30), label, font=FONT, fill=(0, 255, 0))
                    frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        
        # ç»˜åˆ¶å¸§ç‡ï¼ˆä½¿ç”¨PILç»˜åˆ¶ä¸­æ–‡ï¼‰
        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        fps_text = f"FPS: {self.fps:.1f}"
        draw.text((10, 10), fps_text, font=FONT, fill=(0, 255, 0))
        frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        
        return frame
    
    def run(self):
        """è¿è¡Œå®æ—¶æ‰‹åŠ¿è¯†åˆ«"""
        print("å®æ—¶æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿå·²å¯åŠ¨")
        print("ğŸ’¡ æç¤ºï¼š")
        print("   - æŒ‰ 'q' é”®é€€å‡ºï¼ˆå¦‚æœçª—å£å¯ç”¨ï¼‰")
        print("   - æˆ–æŒ‰ Ctrl+C é€€å‡º")
        print()
        
        # çª—å£å¯ç”¨æ€§æ ‡å¿—
        window_available = True
        
        while True:
            try:
                # è¯»å–å¸§
                ret, frame = self.cap.read()
                if not ret:
                    print("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                    break
                
                # é•œåƒç¿»è½¬å¸§
                frame = cv2.flip(frame, 1)
                
                # é¢„å¤„ç†å¸§
                processed_frame = self.preprocess_frame(frame)
                
                # æ£€æµ‹æ‰‹åŠ¿
                results = self.detect_gestures(processed_frame)
                
                # è®¡ç®—å¸§ç‡
                current_time = time.time()
                self.fps = 1 / (current_time - self.prev_time) if (current_time - self.prev_time) > 0 else 0
                self.prev_time = current_time
                
                # ç»˜åˆ¶ç»“æœ
                output_frame = self.draw_results(frame, results)
                
                # æå–è¯†åˆ«ç»“æœï¼ˆç”¨äºç»ˆç«¯è¾“å‡ºï¼‰
                detected_gestures = []
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        conf = float(box.conf[0])
                        cls = int(box.cls[0])
                        if cls in gesture_classes:
                            gesture_name = gesture_classes[cls]
                            detected_gestures.append(f"{gesture_name} ({conf:.2f})")
                
                # å°è¯•æ˜¾ç¤ºå¸§
                if window_available:
                    try:
                        cv2.imshow("å®æ—¶æ‰‹åŠ¿è¯†åˆ«", output_frame)
                        # æŒ‰ 'q' é”®é€€å‡º
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            break
                    except Exception as e:
                        # çª—å£æ˜¾ç¤ºå¤±è´¥ï¼Œåˆ‡æ¢åˆ°ç»ˆç«¯è¾“å‡ºæ¨¡å¼
                        window_available = False
                        print("âš ï¸  çª—å£æ˜¾ç¤ºä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°ç»ˆç«¯è¾“å‡ºæ¨¡å¼")
                        print("ğŸ“‹ è¯†åˆ«ç»“æœå°†è¾“å‡ºåˆ°ç»ˆç«¯")
                        print()
                else:
                    # ç»ˆç«¯è¾“å‡ºæ¨¡å¼
                    if detected_gestures:
                        print(f"[{time.strftime('%H:%M:%S')}] FPS: {self.fps:.1f} | è¯†åˆ«ç»“æœ: {', '.join(detected_gestures)}")
                    else:
                        print(f"[{time.strftime('%H:%M:%S')}] FPS: {self.fps:.1f} | æœªæ£€æµ‹åˆ°æ‰‹åŠ¿")
                    
                    # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¾“å‡ºè¿‡å¿«
                    time.sleep(0.1)
                    
            except KeyboardInterrupt:
                # æ•è· Ctrl+C é€€å‡º
                print()
                print("ğŸ”„ æ­£åœ¨é€€å‡ºç³»ç»Ÿ...")
                break
        
        # é‡Šæ”¾èµ„æº
        self.cap.release()
        try:
            cv2.destroyAllWindows()
        except:
            pass
        print("âœ… å®æ—¶æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿå·²å…³é—­")
    
    def train_model(self, data_yaml, epochs=100, imgsz=640):
        """è®­ç»ƒè‡ªå®šä¹‰æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹"""
        # åŠ è½½YOLOv8æ¨¡å‹è¿›è¡Œè®­ç»ƒ
        model = YOLO('yolov8n.pt')
        results = model.train(
            data=data_yaml,
            epochs=epochs,
            imgsz=imgsz,
            batch=16,
            name='hand_gesture_model'
        )
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("å®æ—¶æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ v1.0")
    print("åŸºäº YOLOv8 å’Œ OpenCV")
    print("=" * 50)
    print()
    
    try:
        # åˆ›å»ºæ‰‹åŠ¿è¯†åˆ«å™¨å®ä¾‹
        recognizer = HandGestureRecognizer()
        # è¿è¡Œå®æ—¶è¯†åˆ«
        recognizer.run()
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print()
        print("ğŸ’¡ å¸¸è§é—®é¢˜è§£å†³æ–¹æ³•:")
        print("1. æ¨¡å‹ä¸‹è½½å¤±è´¥:")
        print("   - æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt")
        print("   - å°†æ¨¡å‹æ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•")
        print()
        print("2. æ‘„åƒå¤´æ— æ³•æ‰“å¼€:")
        print("   - ç¡®ä¿æ‘„åƒå¤´æœªè¢«å…¶ä»–ç¨‹åºå ç”¨")
        print("   - æ£€æŸ¥æ‘„åƒå¤´é©±åŠ¨æ˜¯å¦æ­£å¸¸")
        print("   - å°è¯•ä½¿ç”¨ä¸åŒçš„æ‘„åƒå¤´ç´¢å¼• (ä¿®æ”¹ä»£ç ä¸­çš„ cv2.VideoCapture(0) ä¸º 1, 2 ç­‰)")
        print()
        print("3. OpenCV çª—å£æ˜¾ç¤ºé”™è¯¯:")
        print("   - è¿™æ˜¯ç”±äº OpenCV ç¼–è¯‘é…ç½®é—®é¢˜")
        print("   - å°è¯•ä½¿ç”¨å…¶ä»–ç¯å¢ƒè¿è¡Œ")
        print("   - æˆ–ä½¿ç”¨è¿œç¨‹æ¡Œé¢ç­‰å·¥å…·")
        print()
        print("4. æ€§èƒ½é—®é¢˜:")
        print("   - é™ä½æ‘„åƒå¤´åˆ†è¾¨ç‡")
        print("   - æé«˜ç½®ä¿¡åº¦é˜ˆå€¼ conf")
        print("   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (å¦‚ yolov8n.pt)")
        print()
        print("ğŸ“š è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·æŸ¥çœ‹ README.md æ–‡ä»¶")

if __name__ == "__main__":
    main()
