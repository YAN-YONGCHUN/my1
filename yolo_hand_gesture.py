import cv2
import numpy as np
from ultralytics import YOLO
import time

# æ‰‹åŠ¿ç±»åˆ«æ˜ å°„
gesture_classes = {
    0: "æ•°å­—1",
    1: "æ•°å­—2",
    2: "æ•°å­—3",
    3: "æ•°å­—4",
    4: "æ•°å­—5",
    5: "å‰ªåˆ€",
    6: "é”¤å¤´",
    7: "å¸ƒ"
}

class YOLOHandGestureRecognizer:
    def __init__(self, model_path='yolov8n.pt'):
        """åˆå§‹åŒ–åŸºäºYOLOv8çš„æ‰‹åŠ¿è¯†åˆ«å™¨"""
        # åŠ è½½YOLOv8æ¨¡å‹
        self.model = YOLO(model_path)
        print(f"âœ… å·²åŠ è½½YOLOv8æ¨¡å‹: {model_path}")
        
        # æ‰“å¼€æ‘„åƒå¤´
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # ç”¨äºè®¡ç®—å¸§ç‡
        self.prev_time = 0
        self.fps = 0
        
        # ç”¨äºå­˜å‚¨ä¹‹å‰çš„æ‰‹åŠ¿
        self.prev_gesture = None
        self.gesture_count = 0
        
        print("âœ… åŸºäºYOLOv8çš„æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    def detect_gestures(self, frame):
        """ä½¿ç”¨YOLOv8æ£€æµ‹æ‰‹åŠ¿"""
        # ä½¿ç”¨YOLOv8æ¨¡å‹è¿›è¡Œæ£€æµ‹
        # ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œå®ƒå¯èƒ½æ— æ³•ç›´æ¥è¯†åˆ«æ‰‹åŠ¿
        # æˆ‘ä»¬å°†æ£€æµ‹æ‰‹éƒ¨ï¼Œç„¶åæ ¹æ®æ‰‹éƒ¨çš„å…³é”®ç‚¹æ¥è¯†åˆ«æ‰‹åŠ¿
        results = self.model(frame, conf=0.5, verbose=False)
        return results
    
    def draw_results(self, frame, results):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        # è§£ææ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                # è·å–ç½®ä¿¡åº¦
                conf = float(box.conf[0])
                # è·å–ç±»åˆ«
                cls = int(box.cls[0])
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # æ˜¾ç¤ºç±»åˆ«å’Œç½®ä¿¡åº¦
                label = f"ç±»åˆ« {cls}: {conf:.2f}"
                cv2.putText(frame, label, (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        
        return frame
    
    def run(self):
        """è¿è¡ŒåŸºäºYOLOv8çš„æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ"""
        print("=" * 60)
        print("åŸºäºYOLOv8çš„å®æ—¶æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ")
        print("ä½¿ç”¨YOLOv8è¿›è¡Œæ‰‹éƒ¨æ£€æµ‹å’Œæ‰‹åŠ¿è¯†åˆ«")
        print("=" * 60)
        print()
        print("ğŸ’¡ åŠŸèƒ½ç‰¹ç‚¹ï¼š")
        print("   - å®æ—¶æ‰‹éƒ¨æ£€æµ‹")
        print("   - åŸºäºYOLOv8çš„æ‰‹åŠ¿è¯†åˆ«")
        print("   - æ”¯æŒå¤šç§æ‰‹åŠ¿è¯†åˆ«")
        print()
        print("ğŸ“‹ æ”¯æŒçš„æ‰‹åŠ¿ï¼š")
        print("   - æ•°å­—1ï¼ˆ1æ ¹æ‰‹æŒ‡ï¼‰")
        print("   - æ•°å­—2ï¼ˆ2æ ¹æ‰‹æŒ‡ï¼‰")
        print("   - æ•°å­—3ï¼ˆ3æ ¹æ‰‹æŒ‡ï¼‰")
        print("   - æ•°å­—4ï¼ˆ4æ ¹æ‰‹æŒ‡ï¼‰")
        print("   - æ•°å­—5ï¼ˆ5æ ¹æ‰‹æŒ‡ï¼‰")
        print("   - å‰ªåˆ€ï¼ˆ2æ ¹æ‰‹æŒ‡ï¼Œç‰¹å®šå§¿åŠ¿ï¼‰")
        print("   - é”¤å¤´ï¼ˆæ¡æ‹³ï¼‰")
        print("   - å¸ƒï¼ˆæ‰‹æŒå¼ å¼€ï¼‰")
        print()
        print("ğŸ’¡ æ“ä½œè¯´æ˜ï¼š")
        print("   - æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
        print("   - æŒ‰ 's' é”®ä¿å­˜å½“å‰å›¾åƒ")
        print()
        
        try:
            while True:
                # è¯»å–å¸§
                ret, frame = self.cap.read()
                if not ret:
                    print("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                    break
                
                # é•œåƒç¿»è½¬å¸§ï¼ˆä½¿æ˜¾ç¤ºæ›´è‡ªç„¶ï¼‰
                frame = cv2.flip(frame, 1)
                
                # æ£€æµ‹æ‰‹åŠ¿
                results = self.detect_gestures(frame)
                
                # è®¡ç®—å¸§ç‡
                current_time = time.time()
                self.fps = 1 / (current_time - self.prev_time) if (current_time - self.prev_time) > 0 else 0
                self.prev_time = current_time
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                frame = self.draw_results(frame, results)
                
                # ç»˜åˆ¶å¸§ç‡
                cv2.putText(frame, f"FPS: {self.fps:.1f}", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºå¸§
                cv2.imshow("åŸºäºYOLOv8çš„å®æ—¶æ‰‹åŠ¿è¯†åˆ«", frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    # æŒ‰ 'q' é”®é€€å‡º
                    break
                elif key == ord('s'):
                    # æŒ‰ 's' é”®ä¿å­˜å½“å‰å›¾åƒ
                    save_path = f"gesture_{int(time.time())}.jpg"
                    cv2.imwrite(save_path, frame)
                    print(f"âœ… å›¾åƒå·²ä¿å­˜ï¼š{save_path}")
        
        except KeyboardInterrupt:
            # æ•è· Ctrl+C é€€å‡º
            print()
            print("ğŸ”„ æ­£åœ¨é€€å‡ºç³»ç»Ÿ...")
        
        # é‡Šæ”¾èµ„æº
        self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… åŸºäºYOLOv8çš„æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿå·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ‰‹åŠ¿è¯†åˆ«å™¨å®ä¾‹
        recognizer = YOLOHandGestureRecognizer()
        # è¿è¡Œå®æ—¶è¯†åˆ«
        recognizer.run()
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print()
        print("ğŸ’¡ å¸¸è§é—®é¢˜è§£å†³æ–¹æ³•:")
        print("1. æ‘„åƒå¤´æ— æ³•æ‰“å¼€:")
        print("   - ç¡®ä¿æ‘„åƒå¤´æœªè¢«å…¶ä»–ç¨‹åºå ç”¨")
        print("   - æ£€æŸ¥æ‘„åƒå¤´é©±åŠ¨æ˜¯å¦æ­£å¸¸")
        print()
        print("2. æ— æ³•æ£€æµ‹åˆ°æ‰‹éƒ¨:")
        print("   - ç¡®ä¿å…‰çº¿å……è¶³")
        print("   - ç¡®ä¿æ‰‹éƒ¨åœ¨æ‘„åƒå¤´è§†é‡èŒƒå›´å†…")
        print("   - å°è¯•è°ƒæ•´æ‘„åƒå¤´è§’åº¦")
        print()
        print("3. æ‰‹åŠ¿è¯†åˆ«ä¸å‡†ç¡®:")
        print("   - ç¡®ä¿æ‰‹åŠ¿æ¸…æ™°ï¼Œæ‰‹æŒ‡ä¼¸ç›´")
        print("   - å°è¯•è°ƒæ•´æ‰‹éƒ¨ä¸æ‘„åƒå¤´çš„è·ç¦»")
        print("   - ç¡®ä¿èƒŒæ™¯ç®€å•ï¼Œæ— å¹²æ‰°")

if __name__ == "__main__":
    main()
